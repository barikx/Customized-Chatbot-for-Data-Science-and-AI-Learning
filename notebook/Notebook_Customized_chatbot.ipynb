{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hMahgI9rFrVP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79fac605-1637-4046-d807-553c090c3ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.6/109.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q groq langchain_community langchain_groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from groq import Groq\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain_groq import ChatGroq"
      ],
      "metadata": {
        "id": "nyNIbjKvFscj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "groq_api_key=\"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\"  # Replace with your actual API key"
      ],
      "metadata": {
        "id": "pRRtW9C4FsZk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGroq(\n",
        "    api_key =groq_api_key,\n",
        "    model=\"mixtral-8x7b-32768\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")"
      ],
      "metadata": {
        "id": "bYblpiSlFsVV"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_prompt_template_for_chatbot = \"\"\"\n",
        "You are a knowledgeable assistant specializing in Data Science and Artificial Intelligence (AI).\n",
        "\n",
        "Your primary objective is to assist students by providing clear, concise, and accurate answers to their questions specifically related to Data Science and AI. This includes, but is not limited to, the following topics:\n",
        "- Programming languages and tools: Python, SQL (MySQL, SQLite, MongoDB)\n",
        "- Data visualization tools: Power BI, Tableau\n",
        "- Statistical concepts and methodologies\n",
        "- Machine Learning (ML) techniques and frameworks\n",
        "- MLFlow for managing machine learning workflows\n",
        "- Containerization with Docker\n",
        "- Deep Learning concepts and frameworks\n",
        "- Natural Language Processing (NLP)\n",
        "- Generative AI technologies\n",
        "- Skills required for a career in Data Science and AI\n",
        "\n",
        "When responding, ensure that your answers are focused and straightforward, avoiding unnecessary details. If users ask complex questions, break down your responses into manageable parts and provide step-by-step explanations when needed.\n",
        "\n",
        "Always be polite and encouraging, ensuring that you provide accurate information at all times.\n",
        "\n",
        "If a question is asked that falls outside the realm of Data Science and AI or does not relate to the topics mentioned above, respond with a polite message indicating that the question is unrelated. For example: \"I'm sorry, but that topic is outside the scope of Data Science and AI. I'm unable to provide an answer.\"\n",
        "\n",
        "Remember previous exchanges in the conversation to provide better context for your responses.\n",
        "\n",
        "History: {history}\n",
        "\n",
        "Context: {context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "xQqFiYMxFsTA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(template=custom_prompt_template_for_chatbot,\n",
        "                            input_variables=['history','context', 'question'])\n",
        "\n",
        "memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")"
      ],
      "metadata": {
        "id": "lbolIiehGGve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96a92a01-cf93-4691-c6dc-0c00913affb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-dd3218e8ed5a>:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(input_key=\"question\", memory_key=\"history\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to format output in Markdown\n",
        "def format_output(response):\n",
        "    if isinstance(response, str):\n",
        "        # Check if the response contains code (you can customize this check)\n",
        "        if response.startswith(\"``````\"):\n",
        "            return response  # Return as is if it's already in code block\n",
        "        else:\n",
        "            # Format as markdown for theoretical responses\n",
        "            formatted_response = f\"# Response\\n\\n{response}\"\n",
        "            return formatted_response\n",
        "    return response"
      ],
      "metadata": {
        "id": "8AIPX9XxK6e7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "def invoke_chain(question):\n",
        "    response = chain.invoke({\"history\": memory, \"context\": \"\", \"question\": question})\n",
        "    return format_output(response)"
      ],
      "metadata": {
        "id": "VGXuobIsGUI9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"write a python code to train linear regression model from taking data till predictions\"\n",
        "response = invoke_chain(question)\n",
        "print(response)"
      ],
      "metadata": {
        "id": "9Up-jyB4zwLA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6520eed2-3fb4-430f-f060-c5c237fbb42d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content=\"Sure, I'd be happy to help you with that! Here's a simple example of how you can train a linear regression model using Python and the scikit-learn library. This example assumes that you have a dataset `X` for training features and `y` for the target variable.\\n\\n```python\\n# Import necessary libraries\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.linear_model import LinearRegression\\n\\n# Split the data into training and testing sets\\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n# Create a Linear Regression object\\nmodel = LinearRegression()\\n\\n# Train the model using the training sets\\nmodel.fit(X_train, y_train)\\n\\n# Now the model is trained and you can use it to make predictions\\npredictions = model.predict(X_test)\\n```\\n\\nIn this code:\\n\\n1. We first import the necessary libraries. `train_test_split` is used to split the data into training and testing sets, and `LinearRegression` is the class we use to create our linear regression model.\\n2. We then split the data into training and testing sets. The `test_size` parameter determines the proportion of the data that should be used for testing (in this case, 20%). `random_state` is used for initializing the internal random number generator, which will decide the splitting of data into train and test indices.\\n3. We create a Linear Regression object and fit it to our training data using the `fit` method.\\n4. Finally, we use the trained model to make predictions on our test data.\\n\\nPlease note that this is a very basic example. In a real-world scenario, you would need to preprocess your data, handle missing values, possibly scale/normalize your features, tune your model's hyperparameters, and validate your model's performance using appropriate metrics.\" additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 456, 'prompt_tokens': 380, 'total_tokens': 836, 'completion_time': 0.708229254, 'prompt_time': 0.032180084, 'queue_time': 0.017092034, 'total_time': 0.740409338}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None} id='run-ac39ea5d-3c32-41f4-a395-373d28117f75-0' usage_metadata={'input_tokens': 380, 'output_tokens': 456, 'total_tokens': 836}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    question = input(\"Ask a question (or type 'exit' to quit): \")\n",
        "    if question.lower() == 'exit':\n",
        "        break\n",
        "\n",
        "    response = invoke_chain(question)\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "Ga82r2aBofnV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e00d3c92-5d78-48e9-e258-df7fdb1b0006"
      },
      "execution_count": 10,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ask a question (or type 'exit' to quit): python in data science\n",
            "content='Python is a popular programming language widely used in the field of Data Science due to its simplicity, versatility, and extensive library support. Here are some reasons why Python is preferred for Data Science:\\n\\n1. **Easy to learn**: Python has a simple syntax, making it easy for beginners to learn and understand.\\n\\n2. **Data manipulation**: Libraries like Pandas and NumPy provide efficient data manipulation and analysis capabilities.\\n\\n3. **Data visualization**: Libraries like Matplotlib, Seaborn, and Plotly enable the creation of insightful visualizations to represent data.\\n\\n4. **Machine Learning**: Python offers powerful libraries like Scikit-learn, TensorFlow, and PyTorch for implementing machine learning algorithms.\\n\\n5. **Statistical analysis**: Libraries like SciPy and Statsmodels offer various statistical functions and models for data analysis.\\n\\n6. **Flexibility**: Python can be used for end-to-end Data Science projects, from data cleaning and preprocessing to model building, evaluation, and deployment.\\n\\nTo get started with Python for Data Science, you can follow these steps:\\n\\n1. Install Python and set up your development environment (IDE). Popular IDEs for Data Science include Jupyter Notebook, PyCharm, and Visual Studio Code.\\n\\n2. Learn Python basics, such as variables, data types, loops, functions, and classes.\\n\\n3. Familiarize yourself with essential libraries like NumPy, Pandas, and Matplotlib.\\n\\n4. Practice Data Science tasks, such as data cleaning, data visualization, and machine learning, using real-world datasets.\\n\\n5. Join Data Science communities and forums to learn from others and collaborate on projects.\\n\\nBy following these steps, you can build a strong foundation in Python for Data Science and explore the vast opportunities it offers.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 405, 'prompt_tokens': 369, 'total_tokens': 774, 'completion_time': 0.630172837, 'prompt_time': 0.018603014, 'queue_time': 0.019124523999999997, 'total_time': 0.648775851}, 'model_name': 'mixtral-8x7b-32768', 'system_fingerprint': 'fp_c5f20b5bb1', 'finish_reason': 'stop', 'logprobs': None} id='run-0d6568cd-5417-4210-a507-0ac904a15cca-0' usage_metadata={'input_tokens': 369, 'output_tokens': 405, 'total_tokens': 774}\n",
            "Ask a question (or type 'exit' to quit): exit\n"
          ]
        }
      ]
    }
  ]
}